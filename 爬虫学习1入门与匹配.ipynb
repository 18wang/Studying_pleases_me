{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在莫烦学习\n",
    "https://morvanzhou.github.io/tutorials/data-manipulation/scraping/1-01-understand-website/\n",
    "在 HTML 中, 基本上所有的实体内容, 都会有个 tag 来框住它. 而这个被 tag 住的内容, 就可以被展示成不同的形式, 或有不同的功能. 主体的 tag 分成两部分, header 和 body. 在 header 中, 存放这一些网页的网页的元信息, 比如说 title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#use urllib.request --An extensible library for opening URLs using a variety of protocols\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# if has Chinese, apply decode()\n",
    "html = urlopen(\n",
    "    \"https://morvanzhou.github.io/static/scraping/basic-structure.html\"\n",
    ").read().decode('utf-8')\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 Python 的正则表达式 [RegEx](http://localhost:8888/notebooks/Desktop/notebook/%20RegEx%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E5%AD%A6%E4%B9%A0.ipynb) 进行匹配文字\n",
    "re.findall() 的库说明<br>\n",
    "Definition : findall(pattern, string, flags=0) <br>\n",
    "Type : Function of re module <p>\n",
    "一个很好的学习正则表达式(RegEx)的网站 <br>\n",
    "https://morvanzhou.github.io/tutorials/python-basic/basic/13-10-regular-expression/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "look=re.findall(r\"<title>(.+?)</title>\",html)\n",
    "print(\"\\nPage.title is\",look[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要找到中间的那个段落 < p >, 我们使用下面方法, 因为这个段落在 HTML 中还夹杂着 tab, new line, 所以我们给一个 flags=re.DOTALL 来对这些 tab, 和换行new line 不敏感.<br>\n",
    "不用DOTALL会报错。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "looks=re.findall(r\"<p>(.*?)</p>\",html,flags=re.DOTALL)\n",
    "looks_n=re.findall(r\"<p>(.+?)</p>\",html)\n",
    "print(\"\\nParagraph is:\",looks[0])\n",
    "print(\"\\nParagraph_n is:\",looks_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用beautifulsoup\n",
    "[中文官网](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/#id5)  <br>\n",
    "能够智能协助匹配tag，但是可以发现，每个tag的标志还在，因此我们采用类似字典的方法,用 key 来读取 i[\"href\"]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "htmll = urlopen( \n",
    "    \"https://morvanzhou.github.io/static/scraping/basic-structure.html\"\n",
    ").read().decode('utf-8')\n",
    "contain=BeautifulSoup(htmll,\"lxml\")\n",
    "print(contain)\n",
    "\n",
    "print('\\n\\n',contain.h1)\n",
    "print(contain.a)\n",
    "#只能输出一个.a\n",
    "#你会发现所有的tag都被包含在内，如果你输出contian.p会报错，大概是因为.p包含其他内容\n",
    "\n",
    "a_contain=contain.find_all('a')\n",
    "print('\\n直接输出<a>会以列表形式并显示tag:',a_contain,sep='\\n')\n",
    "a_contain=[i[\"href\"] for i in a_contain]\n",
    "print(a_contain)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配合CSS<br>\n",
    "CSS能够对网站进行很好的**修饰**,修饰一般以class的方式定义在'head'里边,class兼有归类的功能。因此我们可以通过寻找类来找到我们需要的类及类所包含的东西。<p>\n",
    "tag的 class 属性是 多值属性 .按照CSS类名搜索tag时,可以分别搜索tag中的每个CSS类名:<br>\n",
    "css_soup = BeautifulSoup('p class=\"body strikeout\"')<br>\n",
    "css\\_soup.find\\_all(\"p\", **class\\_**= \"strikeout\")<br>\n",
    "#[p class=\"body strikeout\" <br>\n",
    "\n",
    "css\\_soup.find\\_all(\"p\", **class\\_**=\"body\")<br>\n",
    "#[p class=\"body strikeout\"<p>\n",
    "![class.png](attachment:class.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from urllib.request import urlopen\n",
    "html=urlopen( \"https://morvanzhou.github.io/static/scraping/list.html\" ).read().decode('utf-8')\n",
    "#print(html)\n",
    "soup=BeautifulSoup(html,features='lxml')\n",
    "#soup.find_all()可以包含多个参数,两个式子都可以，使用class_是因为class为python保留字\n",
    "\n",
    "#month=soup.find_all('li',{'class':'month'}) #精确匹配的格式\n",
    "\n",
    "month=soup.find_all('li',class_='month') \n",
    "for m in month:\n",
    "    print(m.get_text())\n",
    "print('\\n')\n",
    "date=soup.find_all('ul',class_='jan')\n",
    "for d in date:\n",
    "    print(d.get_text())\n",
    "\n",
    "link=soup.find_all('a',href=re.compile('https'))#'a'是可有可无的\n",
    "print(\"参数href的操作:\\n\",link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**find_all()**接受很多参数，包括 keyword(id、href等等), name(<>中的内容)，class\\_，text<br>\n",
    "![775ca407-14c0-4197-beee-10d650a10943.png](attachment:775ca407-14c0-4197-beee-10d650a10943.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://morvanzhou.github.io/static/img/course_cover/tf.jpg', 'https://morvanzhou.github.io/static/img/course_cover/rl.jpg', 'https://morvanzhou.github.io/static/img/course_cover/scraping.jpg']\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "html=urlopen( \"https://morvanzhou.github.io/static/scraping/table.html\" ).read().decode('utf-8')\n",
    "soup=BeautifulSoup(html,features='lxml')\n",
    "\n",
    "img=soup.find_all('img',src=re.compile(\".*?\\.jpg\"))\n",
    "#精确匹配需要使用大括号,格式为 {关键字类型：正则或字串}\n",
    "#img_links = soup.find_all(\"img\", {\"src\": re.compile('.*?\\.jpg')})\n",
    "img_link=[i[\"src\"] for i in img]\n",
    "print(img_link)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
